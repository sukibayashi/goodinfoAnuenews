{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     stock_id stock_name trading_volume  volume   total_amount    open  \\\n",
      "0        0050     元大台灣50      8,700,172  22,007  1,037,538,973  120.00   \n",
      "1        0051    元大中型100         73,416     173      4,291,980   58.50   \n",
      "2        0052       富邦科技        349,045     765     37,163,057  107.15   \n",
      "3        0053       元大電子         10,094   1,005        603,696   60.10   \n",
      "4        0055   元大MSCI金融        165,794     281      3,717,174   22.42   \n",
      "...       ...        ...            ...     ...            ...     ...   \n",
      "1184     9944         新麗        118,699     137      2,416,253   20.40   \n",
      "1185     9945        潤泰新      6,070,529   3,588    215,079,673   35.45   \n",
      "1186     9946       三發地產      1,767,847     705     24,830,573   13.65   \n",
      "1187     9955         佳龍        768,142     576     19,875,633   26.15   \n",
      "1188     9958        世紀鋼      6,700,967   4,803    786,414,414  115.50   \n",
      "\n",
      "         max     min   close pe_ratio        date  \n",
      "0     120.05  118.80  119.05     0.00  2023-04-19  \n",
      "1      58.55   58.25   58.45     0.00  2023-04-19  \n",
      "2     107.15  105.95  106.15     0.00  2023-04-19  \n",
      "3      60.10   59.60   59.60     0.00  2023-04-19  \n",
      "4      22.49   22.35   22.35     0.00  2023-04-19  \n",
      "...      ...     ...     ...      ...         ...  \n",
      "1184   20.40   20.30   20.35     9.60  2023-04-19  \n",
      "1185   35.70   35.30   35.45    12.22  2023-04-19  \n",
      "1186   14.30   13.65   14.00    32.56  2023-04-19  \n",
      "1187   26.15   25.65   25.65     0.00  2023-04-19  \n",
      "1188  121.00  115.00  115.50    72.64  2023-04-19  \n",
      "\n",
      "[1189 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import typing\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "URL = \"https://www.twse.com.tw/exchangeReport/MI_INDEX?response=json&date={}&type=ALLBUT0999&_={}\"\n",
    "# 網頁瀏覽時, 所帶的 request header 參數, 模仿瀏覽器發送 request\n",
    "HEADER = {\n",
    "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Host\": \"www.twse.com.tw\",\n",
    "    \"Referer\": \"https://www.twse.com.tw/zh/page/trading/exchange/MI_INDEX.html\",\n",
    "    \"sec-ch-ua\": '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"97\", \"Chromium\";v=\"97\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": \"Windows\",\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "}\n",
    "\n",
    "\n",
    "def crawler(parameters:typing.Dict[str, str]) -> pd.DataFrame:\n",
    "    crawler_date = parameters.get(\"crawler_date\", \"\")\n",
    "    crawler_date = crawler_date.replace(\"-\", \"\")\n",
    "    crawler_timestamp = int(datetime.datetime.now().timestamp())\n",
    "\n",
    "    resp = requests.get(\n",
    "        url=URL.format(crawler_date, crawler_timestamp), headers=HEADER\n",
    "    )\n",
    "    \n",
    "    columns = [\n",
    "        \"stock_id\",  # 證券代號\n",
    "        \"stock_name\",  # 證券名稱\n",
    "        \"trading_volume\",  # 成交股數\n",
    "        \"volume\",  # 成交量\n",
    "        \"total_amount\",  # 成交總金額\n",
    "        \"open\",  # 開盤價\n",
    "        \"max\",  # 最高價\n",
    "        \"min\",  # 最低價\n",
    "        \"close\",  # 收盤價\n",
    "        \"pe_ratio\",  # 本益比\n",
    "    ]\n",
    "\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.text)\n",
    "        data = pd.DataFrame(resp_data[\"data9\"])\n",
    "        data = data[[0, 1, 2, 3, 4, 5, 6, 7, 8, 15]]\n",
    "        data.columns = columns\n",
    "        data[\"date\"] = parameters.get(\"crawler_date\", \"\")\n",
    "    else:\n",
    "        data = pd.DataFrame()\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parameters = {\n",
    "        \"crawler_date\": \"2023-04-19\",\n",
    "    }\n",
    "    data = crawler(parameters)\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crawler_date': '2023-04-01'}\n",
      "{'crawler_date': '2023-04-02'}\n",
      "{'crawler_date': '2023-04-03'}\n",
      "{'crawler_date': '2023-04-04'}\n",
      "{'crawler_date': '2023-04-05'}\n",
      "{'crawler_date': '2023-04-06'}\n",
      "{'crawler_date': '2023-04-07'}\n",
      "{'crawler_date': '2023-04-08'}\n",
      "{'crawler_date': '2023-04-09'}\n",
      "{'crawler_date': '2023-04-10'}\n",
      "{'crawler_date': '2023-04-11'}\n",
      "{'crawler_date': '2023-04-12'}\n",
      "{'crawler_date': '2023-04-13'}\n",
      "{'crawler_date': '2023-04-14'}\n",
      "{'crawler_date': '2023-04-15'}\n",
      "{'crawler_date': '2023-04-16'}\n",
      "{'crawler_date': '2023-04-17'}\n",
      "{'crawler_date': '2023-04-18'}\n",
      "{'crawler_date': '2023-04-19'}\n",
      "{'crawler_date': '2023-04-20'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "\n",
    "def gen_task_paramter_list(start_date: str, end_date: str):\n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "    days = (end_date - start_date).days + 1\n",
    "    date_list = [\n",
    "        dict(crawler_date=str(start_date + datetime.timedelta(days=day)))\n",
    "        for day in range(days)\n",
    "    ]\n",
    "    return date_list\n",
    "\n",
    "parameter_list = gen_task_paramter_list(\n",
    "    start_date=\"2023-4-1\",\n",
    "    end_date=\"2023-4-20\",\n",
    ")\n",
    "\n",
    "for parameters in parameter_list:\n",
    "    print(f\"{parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Celery' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcelery\u001b[39;00m \u001b[39mimport\u001b[39;00m Celery\n\u001b[0;32m      3\u001b[0m app \u001b[39m=\u001b[39m Celery(\n\u001b[0;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[39m# 只包含 tasks.py 裡面的程式, 才會成功執行\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     broker\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpyamqp://worker:worker@localhost:5672/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[39m@app\u001b[39m()\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrawler\u001b[39m(\n\u001b[0;32m     16\u001b[0m     dataset: \u001b[39mstr\u001b[39m,\n\u001b[0;32m     17\u001b[0m     parameters: typing\u001b[39m.\u001b[39mDict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[0;32m     18\u001b[0m ):\n\u001b[0;32m     19\u001b[0m     \u001b[39m# 使用 getattr, importlib,\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[39m# 根據不同 dataset, 使用相對應的 crawler 收集資料\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[39m# 爬蟲\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[39m# df = getattr(\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[39m#     importlib.import_module(f\"financialdata.crawler.{dataset}\"),\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[39m#     \"crawler\",\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39m# )(parameters=parameters)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mupload db\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Celery' object is not callable"
     ]
    }
   ],
   "source": [
    "from celery import Celery\n",
    "\n",
    "app = Celery(\n",
    "    \"task\",\n",
    "    # 只包含 tasks.py 裡面的程式, 才會成功執行\n",
    "    include=[\"financialdata.tasks\"],\n",
    "    # 連線到 rabbitmq,\n",
    "    # pyamqp://user:password@localhost:5672/\n",
    "    # 本書的帳號密碼都是 worker\n",
    "    broker=\"pyamqp://worker:worker@localhost:5672/\",\n",
    ")\n",
    "\n",
    "\n",
    "@app()\n",
    "def crawler(\n",
    "    dataset: str,\n",
    "    parameters: typing.Dict[str, str],\n",
    "):\n",
    "    # 使用 getattr, importlib,\n",
    "    # 根據不同 dataset, 使用相對應的 crawler 收集資料\n",
    "    # 爬蟲\n",
    "    # df = getattr(\n",
    "    #     importlib.import_module(f\"financialdata.crawler.{dataset}\"),\n",
    "    #     \"crawler\",\n",
    "    # )(parameters=parameters)\n",
    "    print('df')\n",
    "    print(\"upload db\")\n",
    "    \n",
    "crawler('taiwan','2023-04-20')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
